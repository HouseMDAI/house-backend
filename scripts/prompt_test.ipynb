{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import os \n",
    "import sys \n",
    "import ast\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"\"#os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "max_tokens=150\n",
    "\n",
    "weight = 60\n",
    "age = 20\n",
    "health_problems = \"diabetes, hypertension\"\n",
    "prompt = f\"I am seeking lifestyle advice based on the following information: \\n\\nWeight: {weight} kg\\nAge: {age} years\\nHealth Problems: {health_problems}\\n\\nAdvice:\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"{prompt}\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    max_tokens=max_tokens\n",
    ")\n",
    "\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_list = [\"diabetes\", \"hypertension\"]\n",
    "\", \".join(disease_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.strptime(\"01-02-2013\", '%d-%M-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.prompting import get_response\n",
    "from backend.user_card import get_default_user_card\n",
    "from backend.models import (Question, FilledQuestionary, DoctorResponseAnswer, DoctorResponseQuestionary)\n",
    "\n",
    "card = get_default_user_card()\n",
    "filled_questionary = FilledQuestionary(filledQuestions=dict())\n",
    "message = \"Hallo I am feeling bad today, can you advise?\"\n",
    "\n",
    "questionnaire = get_response(user_card=card, filled_questionary=filled_questionary, message=message)\n",
    "dict_response = ast.literal_eval(questionnaire)\n",
    "\n",
    "for i, text in enumerate(dict_response[\"questions\"]):\n",
    "    print(f\"{i+1} {text['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_questionary.filledQuestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_questionnaire(user_card, message, questionnaire):\n",
    "        response_format = \"\"\"{\"answers\":[{\"text\":\"Yes\"},{\"text\":\"No\"}]}\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Please fill out the Doctor's questionnaire {questionnaire} with very short answers\n",
    "        based on the message: {message} as a real person the medical card: {user_card}.\n",
    "        And give the filled questionnaire without Doctor's questions as a response\n",
    "        The format of your response should be: {response_format}\"\"\"\n",
    "        completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{prompt}\",\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            max_tokens=150\n",
    "        )\n",
    "        filled_questionnaire = completion.choices[0].message.content\n",
    "        return filled_questionnaire\n",
    "\n",
    "filled_questionnaire = fill_questionnaire(card, message, questionnaire)\n",
    "print(filled_questionnaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filled_questionnaire = ast.literal_eval(filled_questionnaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_filled_questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_dict_response = dict()\n",
    "\n",
    "for i, text in enumerate(dict_response[\"questions\"]):\n",
    "    print(f\"{i+1} {text['text']}\")\n",
    "    print(f\"{dict_filled_questionnaire['answers'][i]['text']}\")\n",
    "    filled_dict_response[text['text']] = dict_filled_questionnaire['answers'][i]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_questionary = FilledQuestionary(filledQuestions=filled_dict_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_questionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire = get_response(user_card=card, \n",
    "                             filled_questionary=filled_questionary, \n",
    "                             message=message)\n",
    "\n",
    "dict_response = ast.literal_eval(questionnaire)\n",
    "\n",
    "dict_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text in enumerate(dict_response[\"questions\"]):\n",
    "    print(f\"{i+1} {text['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_questionnaire = fill_questionnaire(card, message, questionnaire)\n",
    "\n",
    "for i, text in enumerate(dict_response[\"questions\"]):\n",
    "    print(f\"{i+1} {text['text']}\")\n",
    "    print(f\"{dict_filled_questionnaire['answers'][i]['text']}\")\n",
    "    filled_dict_response[text['text']] = dict_filled_questionnaire['answers'][i]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_dict_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filled_dict_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire = get_response(user_card=card, \n",
    "                             filled_questionary=filled_dict_response, \n",
    "                             message=message)\n",
    "\n",
    "questionnaire"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
